{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCsLKAlhLRNi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load 'Farm density.csv'\n",
        "farm_density_df = pd.read_csv(\"//content/drive/My Drive/Farm density.csv\")\n",
        "\n",
        "# Load 'Dataset_PRT 564.csv'\n",
        "prt_dataset_df = pd.read_csv(\"/content/drive/My Drive/Dataset_PRT 564.csv\")"
      ],
      "metadata": {
        "id": "95CfmjkXLZHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert region names to lowercase and remove extra spaces for consistency\n",
        "farm_density_df['Region'] = farm_density_df['Region'].str.strip().str.lower()\n",
        "prt_dataset_df['Region'] = prt_dataset_df['Region'].str.strip().str.lower()"
      ],
      "metadata": {
        "id": "rC7tGrb9Lqa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct region names to ensure a successful merge (adjust mapping as needed)\n",
        "region_renames = {\n",
        "    \"yorkshire and the humber\": \"yorkshire and the humber\",\n",
        "    \"east of england\": \"east midlands\",  # Closest matching name\n",
        "    \"south east\": \"south east\",\n",
        "    \"west midlands\": \"west midlands\"\n",
        "}\n",
        "prt_dataset_df['Region'] = prt_dataset_df['Region'].replace(region_renames)"
      ],
      "metadata": {
        "id": "DI3ZghsOLt2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a left join on the 'Region' column\n",
        "merged_df = pd.merge(prt_dataset_df, farm_density_df, on='Region', how='left')"
      ],
      "metadata": {
        "id": "exvdgZ2qLw6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows where farm density information is missing\n",
        "merged_df = merged_df.dropna(subset=['<5 ha', '5<20 ha', '20<50 ha', '50<100 ha', 'â‰¥100 ha', 'Total'])"
      ],
      "metadata": {
        "id": "2obbjSXbL0cW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine 'Year' and 'Month' into a single datetime column named 'Date'\n",
        "merged_df['Date'] = pd.to_datetime(merged_df[['Year', 'Month']].assign(DAY=1))"
      ],
      "metadata": {
        "id": "-AGolSVtL4DQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Label Encoding to categorical text features\n",
        "label_encoders = {}\n",
        "categorical_columns = ['Age', 'Diagnosis', 'Clinical Sign']\n",
        "\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    merged_df[col] = le.fit_transform(merged_df[col])\n",
        "    label_encoders[col] = le  # Store encoder for potential inverse transformation"
      ],
      "metadata": {
        "id": "TM4RznY3L8Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove original 'Year' and 'Month' columns as they are now part of 'Date'\n",
        "merged_df = merged_df.drop(columns=['Year', 'Month'])\n"
      ],
      "metadata": {
        "id": "cfgougcOL-SE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}